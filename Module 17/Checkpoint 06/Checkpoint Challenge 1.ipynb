{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "\n",
    "df = pd.read_csv('imdb_labelled.txt', sep='  \\t', header=None)\n",
    "#df = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header=None)\n",
    "df.columns = ['Sentence', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the bools for the score\n",
    "df.loc[df['Score'] == 0, 'Bool'] = True\n",
    "df.loc[df['Score'] == 1, 'Bool'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words that are in the negative and positive comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = pd.DataFrame([])\n",
    "positive_words = pd.DataFrame([])\n",
    "lower_no_punc = pd.DataFrame([])\n",
    "#[^\\w\\d\\s]+\n",
    "for index in df.index:\n",
    "    if df.iloc[index]['Score'] == 0:\n",
    "        s = df.iloc[index]['Sentence']\n",
    "        out = re.sub(r'[{}]'.format(string.punctuation), ' ', s)\n",
    "        negative_words = negative_words.append(out.lower().split())\n",
    "\n",
    "    if df.iloc[index]['Score'] == 1:\n",
    "        s = df.iloc[index]['Sentence']\n",
    "        out = re.sub(r'[{}]'.format(string.punctuation), ' ', s)\n",
    "        positive_words = positive_words.append(out.lower().split())\n",
    "    lower_no_punc = lower_no_punc.append([out.lower().strip()])\n",
    "\n",
    "lower_no_punc = lower_no_punc.reset_index(drop=True)\n",
    "lower_no_punc.columns = ['Sentence']\n",
    "negative_words = pd.DataFrame(negative_words[0].unique())\n",
    "positive_words = pd.DataFrame(positive_words[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping out the words that are in both positive and negative lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare word lists to each other and remove matching.\n",
    "neg_match = negative_words[0].isin(positive_words[0])\n",
    "pos_match = positive_words[0].isin(negative_words[0])\n",
    "\n",
    "for index in neg_match.index:\n",
    "    if neg_match.iloc[index] == True:\n",
    "        negative_words.drop(index, inplace=True)\n",
    "\n",
    "for index in pos_match.index:\n",
    "    if pos_match.iloc[index] == True:\n",
    "        positive_words.drop(index, inplace=True)\n",
    "        \n",
    "negative_words = negative_words.reset_index(drop=True)\n",
    "positive_words = positive_words.reset_index(drop=True)\n",
    "# Drops anything that is less then three words, reducing match errors.\n",
    "negative_words.drop(negative_words[negative_words[0].str.len() < 3].index, inplace=True)\n",
    "positive_words.drop(positive_words[positive_words[0].str.len() < 3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting the result of the word list to see if it matches the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neg in negative_words[0]:\n",
    "    df[str(neg)] = lower_no_punc['Sentence'].str.contains(str(neg), case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Instantiate the model and store in a variable.\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[negative_words[0]]\n",
    "target = df['Bool']\n",
    "target = target.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 228\n"
     ]
    }
   ],
   "source": [
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "I engineered the features to separate the words from the negative and positive comments and then subtracting out words that showed up in both lists.  This helped to create a good list the is representative of the negative comments.\n",
    "\n",
    "This method could be improved as around 27% of the comments not being accurately represented.  Leaving us with around a 70% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
